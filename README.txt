CIiTで使用していた情報群
verified: 公式or非公式
favorite_count: 総いいね数
ff_rate: フォロワー数とフォロー数の比
listed_count: 総リスト登録数
followers_count: フォロワー数
text_word_count: ツイートの文字数
retweet_count: リツイート数
description_word_count: プロフィールの文字数
account_age: アカウントを作成してからの日数
PN_word_count: ポジネガワード評価値（positive_word - negative_word数）

DataRobotで使用していた特徴量
user_description: プロフィール文(文字数、ですますの数)
 description_length, description_polite_count
user_name: ユーザー名
 user_name_polite_count
やる urls_expanded_urls: 添付URL(あるなし)
like_count: いいね数
やる created_at: 投稿曜日
user_ff_rate: フォロー数とフォロワー数の比
user_listed_count: 総リスト登録数
user_verified: 認証済みアカウントフラグ ... 現状True, falseで表されているため、1, 0の表示に正規化する
user_favorites_count: 総いいね数
dt_age(user_created_at): ユーザー登録年月日
rt_count: リツイート数
user_friends_count: フォロー数
user_statuses_count: 総ツイート数
user_followes_count: フォロワー数
posinega_count(Text_polarity): ツイート本文のポジネガ極性(positive_word - negative_word数)

reply_1h_negative: (リプライも収集対象に入れたいが無料APIだと収集限界があるので難しいかも)

・google cloud platform api key
本番環境で使用する際は使用制限を設定する

テキスト型で非デマの傾向が強い文字群
[公式、アカウント、ニュース、市、情報、です、ます]
これらをカウントして評価とする

やることメモ
×デマと非デマツイート合わせて500件（後藤さんリスペクト）ほどの各情報をAPIで引っ張ってくる
×機械学習（207ページから）を教科書で勉強する
×実際にデータを機械学習して各係数に適切な値を求める（scikit-learnライブラリを使用してもいいかも
×ポジネガ極性のなるべく正しい値を算出する
×Google Cloud Platformの課金がPaypalだと何故か出来ないのでクレジットカードを追加する
×各特徴量の値がどの特徴量名に対応するのか調べる
×ツイートをAPIによって取得する処理と各特徴量を正規化する処理をモジュールごとに分ける
×各値の算出方法を関数化する def
・Pythonでワード検索してその上位50件のツイートを取得して係数を掛けて足す
・フォロワー数とフォロー数の比が逆で計算していたので、正しい計算方法で計算する
・正規化する、上限値を決める
・下位の再現率を測る

参考文献
・『新型コロナウィルスに関するデマツイート検知を NTTデータが検証』
https://www.datarobot.com/jp/blog/datarobot-finds-false-rumors-on-sns/
・ソーシャルメディアにおける災害情報の伝播と感情: 東日本大震災に際する事例
https://www.jstage.jst.go.jp/article/tjsai/31/1/31_NFC-EC1/_pdf/-char/ja

https://newtechnologylifestyle.net/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%80%81%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%A7%E3%81%AE%E5%AD%A6%E7%BF%92%E3%83%87%E3%83%BC%E3%82%BF%E3%81%A8/

scikit-learnで学んだことについて
・特徴量とターゲットでデータを分ける
 例：有益なツイートを1、無益なツイートを0とする
 特徴量(data) = [4.9, 3. , 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2]
 ターゲット(target) = [0, 1, 0]
・全てのデータを学習データとテストデータに分ける
 比率は7:3か8:2が好ましい(一概に正解はない)
 train_test_split関数のtest_sizeで比率を指定する(0~1の小数)
・正解率を表示して理想は0.8ぐらい超えられたらいいかも
・特徴量の重みを表示する
 feature_importances_を使用する
・分類にはランダムフォレストを使用
 決定木を大量に作成し、それぞれの決定木で得られた結果を平均したり多数決をとったりすることで、より汎用性能が高くなっているモデル 

ターゲットの分類方法の詳細(「#コロナ」としてツイートを検索)
0: 情報として全く価値のないツイート
例、今日はいい天気だった、明らかに事実と違うツイート、(ツイート主の行動、感情が分かるツイートは情報に含めない)
1: コロナに関わらず、その情報を得た場合自分の知見が深められるツイート。
例、コロナの今日の感染者数は100人でした。今日は晴れの予報となっております。コロナはただの風邪だよ

研究室輪講で出てきた質問、意見、アドバイス
・ツイートのリツイートで「このツイートはデマだ！」などの書き込みがあった時はデマ度を強くした方がいいのではないか
 - ツイートの取得制限に限りがあり、難しかったので断念
・この正確度という指標は何をもって正確度というのか
 - あくまで大衆的に考えたときに正しい情報として知見が深められるツイートをなるべく上に持ってくる狙い
・ポジネガ極性は長文などに関しては一文ごとにポジティブな部分とネガティブな部分が共存している場合があり、
例えば前半でポジティブな文なのに後半で反語を使ってネガティブな文として作成している場合があるので位置によってポジネガ度を
変えた方がいいのではないか
 - Google Cloud Natural Languageで全て解決、全部考慮した上でポジネガ度を測定してくれる（全てを信じるのは良くないが）

scikit-learnでtwitter_dataset(700件)を特徴量と正解率算出した結果
学習データ:テストデータ = 8:2
正解率：0.8785714285714286
特徴量：
[0.07576589, 0.05626076, 0.02081474, 0.06532632, 0.00431932, 0.0344098,
 0.07515838, 0.05845529, 0.0043411,  0.11462243, 0.11761638, 0.00603965,
 0.09278253, 0.12090105, 0.10188821, 0.05129817]

バックエンド処理
keyword_tweet、ツイートをPythonで取得する→sort_tweet、pandasのDataFrameにツイートデータを変換する→
各特徴量を正規化(0~1の値にする)する→各特徴量に係数を掛けて足す→シグモイド関数で0から1の間の数値にする→
50件のツイートの数値から各偏差値を割り出す→全てのツイートと偏差値のデータをFirebaseに格納する→
Vueでそのデータを取得して表示する
・最初にツイート全てを取得してから特徴量の計算結果を算出する→表示されるのがとても遅いので止めた方がいい
→pandasのメソッドの1つであるapply()を使うことによって解決。applyメソッドは、行全体や列全体に対して、同じ操作をしたいときに使用する
・上限値システムの導入検討
・正規化せずに偏差値を算出した結果、上限などが決められていないため下の値の平均と最高値の差が開きすぎていて
  偏差値にあまり差が出なくてなってしまった。よって正規化＋上限値を設けた方がよいと思われる

フロントエンド処理
html側のinputにキーワードを入力する→そのキーワードでpython側のinputに入力される→
バックエンド処理を行う→取得したツイートをhtml側で表示する

webアプリケーション動作速度：26秒
ターミナル動作速度：22秒